{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d987d1af",
   "metadata": {},
   "source": [
    "Submission Guideline\n",
    "* Do not clear your outputs. This notebook will not have autograder, we will not download and run your solution.\n",
    "* You will have till 11.59 pm tonight to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261f97b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f459f1-c1d2-46f8-b85e-9d459f458312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ce039",
   "metadata": {},
   "source": [
    "# Why do we offload computations to GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f627a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix_a = torch.randn(10000,20000)\n",
    "random_matrix_b = torch.randn(20000,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8827aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n",
      "19.6 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#CPU version\n",
    "out = torch.matmul(random_matrix_a, random_matrix_b)\n",
    "# out = random_matrix_a @ random_matrix_b\n",
    "# out = torch.einsum('ij,jk->ik', random_matrix_a, random_matrix_b)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83488347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move to GPU\n",
    "random_matrix_a = random_matrix_a.to(device)\n",
    "random_matrix_b = random_matrix_b.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c14938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n",
      "24.3 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "#CPU version\n",
    "out = torch.matmul(random_matrix_a, random_matrix_b)\n",
    "# out = random_matrix_a @ random_matrix_b\n",
    "# out = torch.einsum('ij,jk->ik', random_matrix_a, random_matrix_b)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35f460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del random_matrix_a, random_matrix_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f2aec",
   "metadata": {},
   "source": [
    "### 1) Use `%%timeit` to compare performance of the [inverse](https://docs.pytorch.org/docs/stable/generated/torch.inverse.html) and [mean](https://docs.pytorch.org/docs/stable/generated/torch.mean.html) function on CPU and GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8be156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix_inv = torch.randn(10000,10000) # create a random square matrix\n",
    "random_matrix_mean = torch.randn(5,20000) # Compute Mean across rows (5,20000) -> (20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c934e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n",
      "14.2 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "#CPU Inverse \n",
    "out_inv_cpu = torch.inverse(random_matrix_inv) \n",
    "print(out_inv_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18143f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move random_matrix_inv to GPU\n",
    "random_matrix_inv = random_matrix_inv.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8f796b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 10000])\n",
      "352 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "#GPU Inverse \n",
    "out_inv_gpu = torch.inverse(random_matrix_inv) \n",
    "torch.cuda.synchronize() \n",
    "print(out_inv_gpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bff60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000])\n",
      "375 μs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "#CPU Mean \n",
    "out_mean_cpu = torch.mean(random_matrix_mean, dim=0) \n",
    "print(out_mean_cpu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eef9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move random_matrix_mean to GPU\n",
    "random_matrix_mean = random_matrix_mean.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a14248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000])\n",
      "7.22 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 \n",
    "#GPU Mean \n",
    "out_mean_gpu = torch.mean(random_matrix_mean, dim=0) \n",
    "torch.cuda.synchronize() \n",
    "print(out_mean_gpu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fef809a",
   "metadata": {},
   "source": [
    "### 2) Complete the following code-blocks to generate a classifier for predicting 1000 classes.\n",
    "\n",
    "Assume you have input features $\\in R^{512}$, Complete the shapes of weight matrices and einsum strings so that the number of features is [1024,2048,1000] for your three layer network with no bias and relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f85000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = torch.randn(64,1024,512).to(device) # batch size of 64, 1024 pixels, 512 features\n",
    "weight_1 = torch.randn(512, 1024).to(device)\n",
    "weight_2 = torch.randn(1024, 2048).to(device)\n",
    "weight_3 = torch.randn(2048, 1000).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20731d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1000])\n"
     ]
    }
   ],
   "source": [
    "layer_1 = torch.einsum('bpf, fk -> bpk', input_features, weight_1)\n",
    "layer_1 = torch.relu(layer_1) # Suppress Negative Values\n",
    "layer_2 = torch.einsum('bpf, fk -> bpk', layer_1, weight_2)\n",
    "layer_2 = torch.relu(layer_2) # Suppress Negative Values\n",
    "output = torch.einsum('bpf, fk -> bpk', layer_2, weight_3)\n",
    "output = output.mean(dim=1) # Average All Pixels (64,1024,1000) -> (64,1000)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c48818-64f2-4890-9df6-278d77a1b7ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
